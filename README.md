# PerguntAI

**PerguntAI** Ã© um projeto *open source* que disponibiliza uma API para geraÃ§Ã£o gratuita de questÃµes de **Direito Administrativo brasileiro**, utilizando **Large Language Models (LLMs)**. O pÃºblico-alvo sÃ£o estudantes de concursos pÃºblicos (*concurseiros*), auxiliando no estudo ativo por meio da prÃ¡tica de questÃµes.

---

## ğŸš€ VisÃ£o Geral

O projeto consiste em um **webservice baseado em FastAPI**, integrado a um modelo de linguagem executado localmente via **Ollama** e a um mecanismo de busca **OpenSearch**, permitindo a geraÃ§Ã£o, armazenamento e recuperaÃ§Ã£o de conteÃºdos jurÃ­dicos.

---

## ğŸ§° Tecnologias Utilizadas

- **Python 3.12**
- **FastAPI**
- **uv** (gerenciamento de dependÃªncias e ambientes virtuais)
- **Ollama** (execuÃ§Ã£o local de LLMs)
- **OpenSearch** (indexaÃ§Ã£o e busca)
- **Docker & Docker Compose**
- **Makefile** (atalhos para execuÃ§Ã£o)

---

## ğŸ“‹ PrÃ©-requisitos

Antes de executar o projeto, certifique-se de ter instalado:

- **Python 3.12**
- **Docker** e **Docker Compose**
- **uv**
  ```bash
  pip install uv
  ```
- **Ollama**

  https://ollama.com/

ApÃ³s instalar o Ollama, inicie o serviÃ§o:

```bash
ollama serve
```

E faÃ§a o download dos modelos utilizados:

```bash
ollama pull llama3.2:3b
ollama pull bge-m3:latest
```

---

## âš™ï¸ ConfiguraÃ§Ã£o

As configuraÃ§Ãµes da aplicaÃ§Ã£o estÃ£o centralizadas no arquivo:

```
config.yaml
```

### Exemplo:

```yaml
app:
  name: "Gerador de QuestÃµes"
  version: "1.0.0"
  env: "development"
  debug: true
  host: "0.0.0.0"
  port: 8000

ollama:
  base_url: "http://localhost:11434"
  model: "llama3.2:3b"
  embedding_model: "bge-m3:latest"
```

As configuraÃ§Ãµes do **OpenSearch** estÃ£o definidas no arquivo `docker-compose.yml`.

---

## ğŸ³ Subindo o OpenSearch

Na raiz do projeto, execute:

```bash
docker compose up -d
```

ServiÃ§os disponÃ­veis:

- **OpenSearch API**: http://localhost:9200
- **OpenSearch Dashboards**: http://localhost:5601

> âš ï¸ O OpenSearch pode levar alguns segundos para ficar disponÃ­vel apÃ³s a inicializaÃ§Ã£o.

---

## ğŸ“¦ InstalaÃ§Ã£o das DependÃªncias

O projeto utiliza o **uv** para gerenciamento de dependÃªncias.

```bash
make install
```

Para instalar dependÃªncias de desenvolvimento:

```bash
make install-dev
```

---

## â–¶ï¸ Executando a AplicaÃ§Ã£o

ApÃ³s subir o OpenSearch e instalar as dependÃªncias:

```bash
make run
```

A API estarÃ¡ disponÃ­vel em:

```
http://localhost:8000
```

DocumentaÃ§Ã£o automÃ¡tica (Swagger):

```
http://localhost:8000/docs
```

---

## ğŸ§ª Testes

Para executar os testes de serviÃ§o:

```bash
make test_service
```

---

## ğŸ› ï¸ Comandos DisponÃ­veis (Makefile)

| Comando | DescriÃ§Ã£o |
|------|----------|
| `make install` | Cria o ambiente virtual e instala dependÃªncias |
| `make install-dev` | Instala dependÃªncias de desenvolvimento |
| `make run` | Inicia a aplicaÃ§Ã£o FastAPI |
| `make test_service` | Executa testes de serviÃ§o |
| `make clean` | Remove o ambiente virtual |

---

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas!

1. FaÃ§a um fork do repositÃ³rio
2. Crie uma branch para sua feature ou correÃ§Ã£o (`git checkout -b feature/minha-feature`)
3. FaÃ§a commit das alteraÃ§Ãµes (`git commit -m 'Minha contribuiÃ§Ã£o'`)
4. FaÃ§a push para a branch (`git push origin feature/minha-feature`)
5. Abra um Pull Request

---

## ğŸ“„ LicenÃ§a

Este projeto Ã© distribuÃ­do sob a licenÃ§a **MIT**. Consulte o arquivo `LICENSE` para mais detalhes.

---

## ğŸ“Œ Status do Projeto

ğŸš§ Em desenvolvimento ativo.

---

## âœ¨ Agradecimentos

Este projeto foi desenvolvido com fins educacionais e de apoio ao estudo para concursos pÃºblicos, incentivando o uso responsÃ¡vel e acessÃ­vel de tecnologias baseadas em LLMs.

